{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure ML Service to operationalize the TF model\n",
    "\n",
    "Now, we are going to use the Azure ML Service Python SDK to create an image using our custom trained model and deploy this as a web service.\n",
    "\n",
    "Install the AzureML SDK v1.0.8 and follow the steps below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify the version of the SDK, import the module and query the version information -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.8\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "print(azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the workspace require authentication and uses the subscription ID for this process. Provide a unique name for workspace, subscription if, resource group name (which will be created if not existing) and location if needed. This will initiate interactive authentication. Please use the credential provided in the lab UI to connect to the right subscription - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new workspace if needed, takes about 2 minutes\n",
    "from azureml.core import Workspace\n",
    "ws = Workspace.create(name='rlab314ws',\n",
    "                      subscription_id='subscription-id', \n",
    "                      resource_group='rlab314wsrg',\n",
    "                      create_resource_group=True,\n",
    "                      location='eastus2' # Or other supported Azure region   \n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save the workspace informtion to reuse later -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote the config file config.json to: /home/labadmin/aml_config/config.json\n"
     ]
    }
   ],
   "source": [
    "# Save the config \n",
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have saved the workspace information, use the following to reload instead of creating a new one from the scratch -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to existing workspace\n",
    "from azureml.core import Workspace\n",
    "ws=Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring depencies\n",
    "\n",
    "Use the following code to create the environment for your model to run and evaluate the input. Use the following code to create an environment file which will be used to inject the required module when the image is built -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare dependencies\n",
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"numpy\")\n",
    "myenv.add_conda_package(\"pillow\")\n",
    "myenv.add_conda_package(\"tensorflow\")\n",
    "myenv.add_conda_package(\"matplotlib\")\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "    \n",
    "#with open(\"myenv.yml\",\"r\") as f:\n",
    "#    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to register your model with the workspace. You can either point the register function to your model file directly or if you need additional artefacts for your model to function correctly, you can store them in a directory and point this code to that directory instead -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model icondetection\n"
     ]
    }
   ],
   "source": [
    "# Register a trained model\n",
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(model_path = \"tfeval\",\n",
    "                       model_name = \"icondetection\",\n",
    "                       description = \"icon detection model using TF\",\n",
    "                       workspace = ws)\n",
    "\n",
    "print(model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a configuration for the image. This step requires a scoring script which process your inputs once deployed as a web service. Also needed is the information on the runtime and the environment file created earlier -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and register an image\n",
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "# Image configuration\n",
    "image_config = ContainerImage.image_configuration(execution_script = \"score.py\",\n",
    "                                                 runtime = \"python\",\n",
    "                                                 conda_file = \"myenv.yml\",\n",
    "                                                 description = \"icon detection model image using TF\",\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create this image using the code below. This will build the image using the information we have declared above such as the scoring script, runtime and environment file and register it the Azure Container Registry that gets created in the workspace creation steps above -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running.........................................................\n",
      "SucceededImage creation operation finished for image icondetection:1, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "# Register the image from the image configuration in ACR - takes 3-5 mins\n",
    "image = ContainerImage.create(name = \"icondetection\", \n",
    "                              models = [model], #this is the model object\n",
    "                              image_config = image_config,\n",
    "                              workspace = ws\n",
    "                              )\n",
    "\n",
    "image.wait_for_creation(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the image creation fails for any reason, you get your hands on the build log to investigate the errors -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the logs if needed\n",
    "#print(image.image_build_log_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to push create a web service. Using the Azure ML SDK, you can used this image to to creat web service running on Azure Container Instance, AKS, IOT Edge or even, FPGA. In this example, we are using ACI to create a configuration of the container group and use the image that we created earlier to create a web service -  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating service\n",
      "Running....................................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "# Deploy to ACI - takes 3-4 mins\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 2, \n",
    "                                               memory_gb = 2, \n",
    "                                               tags = {\"data\": \"icon detection web service\", \"type\": \"icon detection\"}, \n",
    "                                               description = 'TF Object Detection model for icon detection')\n",
    "\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "service_name = 'aci-id-1'\n",
    "service = Webservice.deploy_from_image(deployment_config = aciconfig,\n",
    "                                            image = image,\n",
    "                                            name = service_name,\n",
    "                                            workspace = ws)\n",
    "service.wait_for_deployment(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the service state and if needed the deployment logs to investigate if there were any error in the process -\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "print(service.state)\n",
    "#service.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the deployment was succesfull, you can use the scoring_uri() to get the scoring URL which you can call from your applications -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://52.151.224.120:80/score'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the scorig URI\n",
    "service.scoring_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code can be used to call this endpoint with the required parameters to get the predictions from the model -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST to url http://52.151.224.120:80/score\n",
      "prediction: <html>\r\n",
      "<head><title>502 Bad Gateway</title></head>\r\n",
      "<body bgcolor=\"white\">\r\n",
      "<center><h1>502 Bad Gateway</h1></center>\r\n",
      "<hr><center>nginx/1.10.3 (Ubuntu)</center>\r\n",
      "</body>\r\n",
      "</html>\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the endpoint\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "input_data = \"{\\\"data\\\": [\\\"some data\\\"]}\"\n",
    "\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "resp = requests.post(service.scoring_uri, input_data, headers=headers)\n",
    "\n",
    "print(\"POST to url\", service.scoring_uri)\n",
    "print(\"prediction:\", resp.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
