{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning and artificial intelligence are becoming prevalent in the software industry. While there is Pre-built AI & conversational AI,  we'd still run into customer scenarios when custom model / code development is required. And it is essential  to get insights into what it's like To bring these scenarios to life by extending current work Or building from scratch \n",
    "One of the common areas of artificial intelligence is Computer vision and in it, specifically object detection. \n",
    "The lab is designed to help you understand at a very high level The constructs and steps involved in an object detection scenario. Many models and techniques exist in the market we will be using tensorflow  and faster-RCNN model for this lab. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Transfer Learning? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer Learning is a branch of Machine Learning which builds custom models on top of existing models. Example, RESNET models  trained on ImageNet & COCO datasets, can be extended to identify objects outside of the above mentioned datasets. Advantages :\n",
    "1. Less Data\n",
    "2. Use all the goodness of parent or base model.\n",
    "3. Training new models is faster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The lab scenario \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will develop a model to identify & segment the app icons in given input image/video. \n",
    "We will start by creating & prr-processing input data for the experiment, followed by configuring training, running modell training & exporting the trained model for inference. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Object Detection?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object Detection is a type of artificial intelligence task which tries to identify (predict) the object in given input. If you have worked with imgage classification scenarios, then learning object detection should be easier for you. Best way is to start with concepts related to Convolution, Deep Learning and other Digital processing if you want to dig deeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Approach "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we have done a lot of work for you have a seamless lab & learning experience, we have primarily built this lab of top of tensorflow object detection steps. The lab environments already has he below steps performed :\n",
    "1. Downloading the tensorflow github repo for object detection\n",
    "2. Generating supporting files (protocol buffers)\n",
    "3. Ensuring other supporting packages related to image processing are installed.\n",
    "4. Downloading pre-ran / pre-built models so that you can complete the lab in allocated time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ~/ready-labs/tf-files/research/object_detection/builders/model_builder_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that all input files have same resolution (size) for a more accurate model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - We will use VOTT tool to first annotate objects and specify location by drawing bounding box around the object of interest (in this case, app icons)\n",
    " - For the session, we will be working with only 6 app icons.\n",
    " - We will resize all input images to 500x500 \n",
    " - Resize code available here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download the VOTT Tool from [here](https://github.com/Microsoft/VoTT/releases/download/1.5.0/VoTT-win32-x64.zip) \n",
    "- We will use the 'PASCAL VOC' format to export the tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps to be performed for models\n",
    "# copy data2 to custom-training\n",
    "#create model_files directory in custom-training & sub-directory called \n",
    "#copy from storage (Ashish) contents of data2 folder\n",
    "#create a train folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image tagging/preprocessing=.. talk about formats, like Pascal VOC, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download models (ignore for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from distutils.version import StrictVersion\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "os.chdir(rootdir)  \n",
    "\n",
    "\n",
    "rootdir = '/home/labadmin/ready-labs/tf-files/research/object_detection/custom-training/'\n",
    "labels_dir = 'data2/'\n",
    "model_extract_dir = 'model_test'  # insert folder name here\n",
    "\n",
    "os.mkdir(model_extract_dir)\n",
    "\n",
    "MODEL_NAME = 'faster_rcnn_resnet101_coco_2018_01_28'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join(labels_dir, 'mscoco_label_map.pbtxt')\n",
    "opener = urllib.request.URLopener()\n",
    "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, model_extract_dir + MODEL_FILE)\n",
    "tar_file = tarfile.open(MODEL_FILE)\n",
    "tar_file.extractall(path=model_extract_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy the pipeline config file to the custom directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing : creating inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd /home/labadmin/ready-labs/tf-files/research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%mkdir object_detection/custom-training/models/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python /dataset_tools/create_pascal_tf_record.py --output_path=object_detection/custom-training/data2/train/pascal.record --data_dir=object_detection/custom-training/data2/train --set=train --label_map_path=object_detection/custom-training/data2/train/pascal_label_map.pbtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Pay attention to comments in the code below. Inputs needed</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "r\"\"\"Convert raw PASCAL dataset to TFRecord for object_detection.\n",
    "\n",
    "Example usage:\n",
    "    python object_detection/dataset_tools/create_pascal_tf_record.py \\\n",
    "        --data_dir=/home/user/VOCdevkit \\\n",
    "        --year=VOC2012 \\\n",
    "        --output_path=/home/user/pascal.record\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import hashlib\n",
    "import io\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from lxml import etree\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import dataset_util\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "\n",
    "input_data_dir = rootdir + 'data2/test' #toggle here between train & test\n",
    "input_set_flag ='val' #toggle for tarin or val[idation]\n",
    "input_annotations_dir = 'Annotations' \n",
    "output_path = rootdir + 'data2/test/pascal.record' #toggle for train  or val folders\n",
    "label_map_path = rootdir + 'data2/test/pascal_label_map.pbtxt' #toggle for train  or val folders\n",
    "ignore_difficult_instances = False\n",
    "\n",
    "flags = tf.app.flags\n",
    "\n",
    "SETS = ['train', 'val', 'trainval', 'test']\n",
    "classes_texts = ['camera','phone','calendar','mail','message']\n",
    "\n",
    "if input_set_flag not in SETS:\n",
    "    raise ValueError('set must be in : {}'.format(SETS))\n",
    "    \n",
    "data_dir = input_data_dir #FLAGS.data_dir\n",
    "\n",
    "writer = tf.python_io.TFRecordWriter(output_path) #FLAGS.output_path\n",
    "\n",
    "label_map_dict = label_map_util.get_label_map_dict(label_map_path) #FLAGS.label_map_path\n",
    "\n",
    "for class_ in classes_texts:\n",
    "    examples_path = os.path.join(data_dir, 'ImageSets', 'Main',\n",
    "                                 class_ + '_'+ input_set_flag +'.txt')\n",
    "    annotations_dir = os.path.join(data_dir, input_annotations_dir)\n",
    "    examples_list = dataset_util.read_examples_list(examples_path)\n",
    "    \n",
    "    for idx, example in enumerate(examples_list):\n",
    "      if idx % 100 == 0:\n",
    "        logging.info('On image %d of %d', idx, len(examples_list))\n",
    "      if(example != ''):\n",
    "        path = os.path.join(annotations_dir, example + '.xml')\n",
    "        with tf.gfile.GFile(path, 'r') as fid:\n",
    "          xml_str = fid.read()\n",
    "        xml = etree.fromstring(xml_str)\n",
    "        data = dataset_util.recursive_parse_xml_to_dict(xml)['annotation']\n",
    "\n",
    "        tf_example = dict_to_tf_example(data, input_data_dir, label_map_dict,\n",
    "                                      ignore_difficult_instances)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "\n",
    "writer.close()\n",
    "\n",
    "def dict_to_tf_example(data,\n",
    "                       dataset_directory,\n",
    "                       label_map_dict,\n",
    "                       ignore_difficult_instances=False,\n",
    "                       image_subdirectory='JPEGImages'):\n",
    "  \"\"\"Convert XML derived dict to tf.Example proto.\n",
    "\n",
    "  Notice that this function normalizes the bounding box coordinates provided\n",
    "  by the raw data.\n",
    "\n",
    "  Args:\n",
    "    data: dict holding PASCAL XML fields for a single image (obtained by\n",
    "      running dataset_util.recursive_parse_xml_to_dict)\n",
    "    dataset_directory: Path to root directory holding PASCAL dataset\n",
    "    label_map_dict: A map from string label names to integers ids.\n",
    "    ignore_difficult_instances: Whether to skip difficult instances in the\n",
    "      dataset  (default: False).\n",
    "    image_subdirectory: String specifying subdirectory within the\n",
    "      PASCAL dataset directory holding the actual image data.\n",
    "\n",
    "  Returns:\n",
    "    example: The converted tf.Example.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: if the image pointed to by data['filename'] is not a valid JPEG\n",
    "  \"\"\"\n",
    "  \n",
    "  img_path = os.path.join(image_subdirectory, data['filename'])\n",
    "  full_path = os.path.join(dataset_directory, img_path)\n",
    "  full_path = full_path + '.' + data['path'].rsplit('.',2)[1] #extension #file_extension \n",
    "  with tf.gfile.GFile(full_path, 'rb') as fid:\n",
    "    encoded_jpg = fid.read()\n",
    "  encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "  image = PIL.Image.open(encoded_jpg_io)\n",
    "  if image.format != 'JPEG':\n",
    "    raise ValueError('Image format not JPEG')\n",
    "  key = hashlib.sha256(encoded_jpg).hexdigest()\n",
    "\n",
    "  width = int(data['size']['width'])\n",
    "  height = int(data['size']['height'])\n",
    "\n",
    "  xmin = []\n",
    "  ymin = []\n",
    "  xmax = []\n",
    "  ymax = []\n",
    "  classes = []\n",
    "  classes_text  = []\n",
    "  \n",
    "  truncated = []\n",
    "  poses = []\n",
    "  difficult_obj = []\n",
    "  if 'object' in data:\n",
    "    for obj in data['object']:\n",
    "      difficult = bool(int(obj['difficult']))\n",
    "      if ignore_difficult_instances and difficult:\n",
    "        continue\n",
    "\n",
    "      difficult_obj.append(int(difficult))\n",
    "\n",
    "      xmin.append(float(obj['bndbox']['xmin']) / width)\n",
    "      ymin.append(float(obj['bndbox']['ymin']) / height)\n",
    "      xmax.append(float(obj['bndbox']['xmax']) / width)\n",
    "      ymax.append(float(obj['bndbox']['ymax']) / height)\n",
    "      classes_text.append(obj['name'].encode('utf8'))\n",
    "      classes.append(label_map_dict[obj['name']])\n",
    "      truncated.append(int(obj['truncated']))\n",
    "      poses.append(obj['pose'].encode('utf8'))\n",
    "\n",
    "  example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': dataset_util.int64_feature(height),\n",
    "      'image/width': dataset_util.int64_feature(width),\n",
    "      'image/filename': dataset_util.bytes_feature(data['filename'].encode('utf8')),\n",
    "      'image/source_id': dataset_util.bytes_feature(data['filename'].encode('utf8')),\n",
    "      'image/key/sha256': dataset_util.bytes_feature(key.encode('utf8')),\n",
    "      'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "      'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),\n",
    "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmin),\n",
    "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmax),\n",
    "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymin),\n",
    "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymax),\n",
    "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "      'image/object/difficult': dataset_util.int64_list_feature(difficult_obj),\n",
    "      'image/object/truncated': dataset_util.int64_list_feature(truncated),\n",
    "      'image/object/view': dataset_util.bytes_list_feature(poses),\n",
    "  }))\n",
    "  return example\n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the above commands with set=val & updated file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 object_detection/dataset_tools/create_pascal_tf_record.py --output_path=object_detection/custom-training/data2/test/pascal.record --data_dir=object_detection/custom-training/data2/test --set=val --label_map_path=object_detection/custom-training/data2/test/pascal_label_map.pbtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with RESNET101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locate and modify the pipeline.config or the faster_rcnn_resnet101_coco.config as :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- update config file\n",
    "- num classes : 6\n",
    "- input_path : line 30\n",
    "- label_map_path :  line 132\n",
    "- eval_config : max evals = 3\n",
    "- train_input_reader : input_path line 116\n",
    "- label_map_path : line 118\n",
    "- fine_tune_checkpoint : line 106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Binary to run train and evaluation on object detection model.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from absl import flags\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection import model_hparams\n",
    "from object_detection import model_lib\n",
    "\n",
    "modeldir = rootdir + 'model_files'\n",
    "train_dir = rootdir + modeldir + 'train'\n",
    "pipeline_config_path_custom = rootdir + 'faster_rcnn_resnet101_coco.config'\n",
    "\n",
    "#update_model_dir\n",
    "#flags.DEFINE_string(\n",
    "#    'model_dir', None, 'Path to output model directory '\n",
    "#'where event and checkpoint files will be written.')\n",
    "\n",
    "#update pipeline config\n",
    "#flags.DEFINE_string('pipeline_config_path', pipeline_config_path, 'Path to pipeline config '\n",
    "#                    'file.')\n",
    "\n",
    "#not mandatory  : start\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "#not mandatory end\n",
    "\n",
    "#flags.mark_flag_as_required('model_dir')\n",
    "#flags.mark_flag_as_required('pipeline_config_path')\n",
    "config = tf.estimator.RunConfig(model_dir=modeldir)\n",
    "\n",
    "train_and_eval_dict = model_lib.create_estimator_and_inputs(\n",
    "      run_config=config,\n",
    "      hparams=model_hparams.create_hparams(FLAGS.hparams_overrides),\n",
    "      pipeline_config_path= pipeline_config_path_custom, #FLAGS.pipeline_config_path,\n",
    "      train_steps=FLAGS.num_train_steps,\n",
    "      sample_1_of_n_eval_examples=FLAGS.sample_1_of_n_eval_examples,\n",
    "      sample_1_of_n_eval_on_train_examples=(\n",
    "          FLAGS.sample_1_of_n_eval_on_train_examples))\n",
    "estimator = train_and_eval_dict['estimator']\n",
    "train_input_fn = train_and_eval_dict['train_input_fn']\n",
    "eval_input_fns = train_and_eval_dict['eval_input_fns']\n",
    "eval_on_train_input_fn = train_and_eval_dict['eval_on_train_input_fn']\n",
    "predict_input_fn = train_and_eval_dict['predict_input_fn']\n",
    "train_steps = train_and_eval_dict['train_steps']\n",
    "\n",
    "if FLAGS.checkpoint_dir:\n",
    "    if FLAGS.eval_training_data:\n",
    "      name = 'training_data'\n",
    "      input_fn = eval_on_train_input_fn\n",
    "    else:\n",
    "      name = 'validation_data'\n",
    "      # The first eval input will be evaluated.\n",
    "      input_fn = eval_input_fns[0]\n",
    "    if FLAGS.run_once:\n",
    "      estimator.evaluate(input_fn,\n",
    "                         num_eval_steps=None,\n",
    "                         checkpoint_path=tf.train.latest_checkpoint(\n",
    "                             FLAGS.checkpoint_dir))\n",
    "    else:\n",
    "      model_lib.continuous_eval(estimator, FLAGS.checkpoint_dir, input_fn,\n",
    "                                train_steps, name)\n",
    "else:\n",
    "    train_spec, eval_specs = model_lib.create_train_and_eval_specs(\n",
    "        train_input_fn,\n",
    "        eval_input_fns,\n",
    "        eval_on_train_input_fn,\n",
    "        predict_input_fn,\n",
    "        train_steps,\n",
    "        eval_on_train_data=False)\n",
    "\n",
    "    # Currently only a single Eval Spec is allowed.\n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export & host in ACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#file actaull inside /.../// in tensorflow spurce. copied here just for demo/lab\n",
    "from object_detection.utils import dataset_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export resnet101 with more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the value of the max ckpt number\n",
    "#run the script below\n",
    "#copy  file export_inference_graph.py from ~/ready-labs/tf-files/research/object_detection/ to custom-training folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 object_detection/custom-training/export_inference_graph.py --input_type=image_tensor --pipeline_config_path=object_detection/custom-training/faster_rcnn_resnet101_coco.config --trained_checkpoint_prefix=object_detection/custom-training/model_final/model.ckpt-296 --output_directory=object_detection/custom-training/fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Ensure to upload test images to the object_detection/test_images folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the object detection notebook [Object detection notebook](tf-files/research/object_detection/object_detection_tutorial.ipynb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment the Download model code and the following changes :\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MODEL_NAME = 'custom-training/fine_tuned_model/\n",
    "- PATH_TO_LABELS = os.path.join('custom-training/data2/train', 'pascal_label_map.pbtxt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python SDK. ACI & logic apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
